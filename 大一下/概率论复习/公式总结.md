# 前言

会用章节分割公式，每个公式会备注参量意义、大致推导方法、使用条件等

结合题目了解到底怎么用的

# 事件的运算

## 基本事件运算符、运算律

不相容、互斥事件：$A\cap B=\varnothing$

逆事件、对立事件：$A\cup B=S \ \&\ A\cap B=\varnothing $

逆事件运算符：$\overline A=S-A$



运算规律：

* 结合律：$A\cup B=B\cup A;A\cap B =B\cap A$
* 结合律：$A\cup (B\cup C)=(A\cup B)\cup C \\ A\cap (B\cap C)=(A\cap B)\cap C$
* 分配律：$A\cup (B\cap C)=(A\cup B)\cap (A\cup C) \\ A\cap (B\cup C)=(A\cap B)\cup (A\cap C)$
* 摩根定律：$\overline{A\cup B}=\overline{A}\cap\overline{B};\overline{A\cap B}=\overline{A}\cup\overline{B}$
* 三结合率：$(A\cup B)\cap (A\cup C)\cap(B\cup C)=AB\cup AC \cup BC$
* 差事件拓展：$A-B=A-AB=A\overline{B}=A\cap \overline B$

## 概率运算性质

* $P(\varnothing)=0;P(A)\le 1$
* 有限可加性：$A_i(i\in N_+)$两两互不相容，则$P(A_1\cup A_2 \cup \cdots\cup A_n)=P(A_1)+P(A_2)+\cdots+P(A_n)$
* 设$A,B$两个事件，若$A\subset B$，则$P(B-A)=P(B-AB)=P(B)-P(A);P(B)\ge P(A)$
* $P(\overline A)=1-P(A)$
* 加法公式：$P(A\cup B)=P(A)+P(B)-P(AB) \\ P(A_1\cup A_2\cup A_3)=P(A_1)+P(A_2)+P(A_3)-P(A_1A_2)-P(A_1A_3)-P(A_2A_3)+P(A_1A_2A_3)$
* 对于任意多事件：$P(A_1\cup A_2\cup \cdots \cup A_n)=\sum\limits_{i=1}\limits^{n}P(A_i)-\sum\limits_{1\le i<<j \le n}P(A_iA_j)+\sum\limits_{1\le i<j<k\le n}P(A_iA_jA_k)+(-1)^{n-1}P(A_1A_2\cdots A_n)$

## 条件概率

### 定义

设两个事件$A,B$，且$P(A)>0$，则$P(B|A)=\frac{P(AB)}{P(A)}$为事件$A$发生下事件$B$发生的条件概率

### 性质

* 可列可加性：$P(B_1\cup B_2|A)=P(B_1|A)+P(B_2|A)-P(B_1B_2|A)$
* 乘法定理：$P(AB)=P(B|A)P(A) \\ P(ABC)=P(C|AB)P(B|A)P(A)$

## 全概率和贝叶斯

设$S$为试验$E$的样本空间，$B_1,B_2,\cdots ,B_n$为$E$的一组事件，如果

$ (i):B_iB_j=\varnothing , i\not= j,\ \ i,j=1,2,\cdots ,n; \\ (ii):B_1\cup B_2\cup \cdots \cup B_n=S$

则称$B_1,B_2,\cdots,B_n$是样本空间$S$的一个划分，每一次试验，$B$中必有且仅有一个发生



设$S$为试验$E$的样本空间，A为$E$的事件，$B_1,B_2,\cdots ,B_n$为$S$的一个划分，且$P(B_i)>0(i=1,2,\cdots,n)$，则

全概率公式：$P(A)=\sum\limits_{i=1}\limits^{n}P(A|B_i)P(B_i)$

贝叶斯公式(要求$P(A)>0$)：$P(B_i|A)=\frac{P(A|B_i)P(B_i)}{\sum\limits_{j=1}\limits^{n}P(A|B_j)P(B_j)},i=1,2,\cdots,n$



## 独立性

### 定义

设$A,B$两个事件，如果满足$P(AB)=P(B|A)P(A)=P(A)P(B)$，则称事件$A,B$相互独立，简称$A,B$独立

如果$P(A)>0,P(B)>0$，独立和互斥不能同时成立！因为独立指一种发生于另一种无关，互斥是一种发生另一个绝不发生

对于三个事件$A,B,C$，如果$\begin{cases}P(AB)=P(A)P(B) \\ P(BC)=P(B)P(C) \\ P(AC)=P(A)P(C) \\ P(ABC)=P(A)P(B)P(C)\end{cases}$，则称$A,B,C$相互独立

多个事件相互独立的定义类似，对于$n$个相互独立的事件，其中的$\forall k<n$个事件也是独立的

### 定理

对于$A,B$两事件，$P(A)>0$，$A,B$相互独立 与 $P(B|A)=P(B)$  互为充要条件

若$A,B$相互独立，则 $\overline A$与$\overline B$、$A$与$\overline B$、$\overline A$与$B$ 也相互独立





# 多维随机变量及其分布

## 边缘概率分布、条件分布和相互独立

### 边缘分布

==注意求边缘概率分布的时候一定要讨论$f=0$的情况！不然就是不完整的答案！==

离散：$\begin{cases}p_{i\cdot}=\sum\limits_{j=1}\limits^{\infty}p_{ij}=P\{X=x_i\} & 关于X的边缘分布律 \\ p_{\cdot j}=\sum\limits_{i=1}\limits^{\infty}p_{ij}=P\{Y=y_j\} & 关于Y的边缘分布律\end{cases}$

连续：$\begin{cases}f_X(x)=\int_{-\infty}^{\infty}f(x,v)\rm{dv} & 关于X的边缘概率密度，求积分时x当作一个常量 \\ f_Y(y)=\int_{-\infty}^{\infty}f(u,y)\rm{du} & 关于Y的边缘概率密度，求积分时y当作一个常量 \end{cases}$



注意这里==离散时讨论的是具体点，连续时讨论的是密度函数==

一般边缘分布不能推导出联合分布

### 条件分布

离散：$\begin{cases} P\{X=x_i|Y=y_j\}=\frac{P\{X=x_i,Y=y_j\}}{P\{Y=y_j\}}=\frac{p_{ij}}{p_\cdot j} &i=1,2,\cdots & Y=y_i下随机变量X的条件分布律 \\ P\{Y=y_j|X=x_i\}=\frac{P\{Y=y_j,X=x_i\}}{P\{X=x_i\}}=\frac{p_{ij}}{p_{i\cdot}} & j=1,2,\cdots & X=x_i下随机变量Y的条件概率分布\end{cases}$

连续：如果对于固定的$y_0$，$f_Y(y_0)>0$，则称$\frac{f(x,y)}{f_Y(y)}$为在$Y=y$条件下的$X$的条件概率密度，记$f_{X|Y}(x|y)=\frac{f(x,y)}{f_Y(y)}$

注意，无论是离散还是连续，讨论的时候==条件都是某一个值(如$Y=y$)==，而==变量在离散时讨论的是具体点，在连续时讨论的是密度函数==

### 独立性

离散：$P(X=x_i,Y=y_j)=P(X=x_i)P(Y=y_j)$

连续：$F(x,y)=F_X(x)F_Y(y),f(x,y)=f_X(x)f_Y(y)$

两个以上的变量的独立性见课本75页，太多了就不记录了



## 两个随机变量的函数的分布（仅讨论连续型）

==这里一定要注意范围！==

### $Z=X+Y$型

设$(X,Y)$为二维连续随机变量，具有概率密度$f(x,y)$，则$Z=X+Y$仍为连续型随机变量

其概率密度：$\begin{array}{l} f_{X+Y}(z)=\int_{-\infty}^{+\infty}f(z-v,v)\rm{dv}\\f_{X+Y}(z)=\int_{-\infty}^{+\infty}f(u,z-u)\rm{du}\end{array}$

如果$X,Y$相互独立，又有边缘密度函数$f_X(x),f_Y(y)$，则：$\begin{array}{l}f_{X+Y}(z)=\int_{-\infty}^{+\infty}f_X(z-v)f_Y(v)\rm{dv}\\f_{X+Y}(z)=\int_{-\infty}^{+\infty}f_X(u)f_Y(z-u)\rm{du}\end{array}$

对于两个正态分布（$X\sim N(\mu_1,\sigma^2_1),Y\sim N(\mu_2,\sigma^2_2)$），如果其相互独立的话，有：$mX+nY\sim (m\mu_1+n\mu_2,m^2\sigma^2_1+n^2\sigma^2_2)$

### $Z=\frac Y X$和$Z=XY$型

设$(X,Y)$为二维连续随机变量，具有概率密度$f(x,y)$，则$Z=\frac Y X$、$Z=\frac X Y$和$Z=XY$仍是连续型随机变量

其概率密度：$\begin{array}{l}f_{Y/X}(z)=\int_{-\infty}^{+\infty}|x|f(x,xz)\rm{dx}\\f_{X/Y}(z)=\int_{-\infty}^{+\infty}|y|f(yz,y)\rm{dy}\\f_{XY}(z)=\int_{-\infty}^{+\infty}\frac 1 {|x|}f(x,\frac z x)\rm{dx}\end{array}$

### $M=max\{X,Y\}$和$N=min\{X,Y\}$型

设$X,Y$**相互独立**，分布函数分别为$F_X(x),F_Y(y)$

则$\begin{array}{l}F_{max}(z)=F_X(x)F_Y(y)\\F_{min}(z)=1-[1-F_X(z)][1-F(z)]\end{array}$





# 随机变量数字特征

## 数学期望和方差

### 定义表达式

* 数学期望

  离散（$P\{X=x_k\}=p_k,k=1,2,\cdots$）：$E(X)=\sum\limits_{k=1}\limits^{\infty}x_kp_k$（如果其绝对收敛的话）

  连续（密度函数$f(x)$）：$E(x)=\int_{-\infty}^{+\infty}xf(x)\rm{dx}$（如果其存在的话）

* 随机变量函数的期望

  如果$Y=g(X)$（$g(X)$连续）

  离散：$E(Y)=E[g(X)]=\sum\limits_{k=1}\limits^{\infty}g(x_k)p_k$

  连续：$E(Y)=E[g(X)]=\int_{-\infty}^{+\infty}g(x)f(x)\rm{dx}$

  （其实平常应用的时候都是无意识地就用上了233）

* 方差

  本质就是函数$[X-E(X)]^2$的数学期望

  离散：$D(X)=\sum\limits_{k=1}\limits^{\infty}[x_k-E(X)]^2p_k$

  连续：$ D(X)=\int_{-\infty}^{+\infty}[x-E(X)]^2f(x)\rm{dx}$

  

### 常见分布的数学期望和分布

| 分布名称 |         参数表          |                             分布                             |    数学期望     |         方差         |
| :------: | :---------------------: | :----------------------------------------------------------: | :-------------: | :------------------: |
| 泊松分布 |   $X\sim\pi(\lambda)$   | $P\{X=k\}=\frac{\lambda^ke^{-\lambda}}{k!}\ (k=0,1,2,\cdots,\lambda>0)$ |    $\lambda$    |      $\lambda$       |
| 均匀分布 |     $X\sim U(a,b)$      | $f(x)=\begin{cases}\frac{1}{b-a},\ &a<x<b \\ 0,\ &others\end{cases}$ | $\frac {a+b} 2$ | $\frac{(b-a)^2}{12}$ |
| 指数分布 |    $X\sim E(\theta)$    | $f(x)=\begin{cases}\frac{1}{\theta}e^{-x/\theta},\ &x>0 \\ 0,\ &x\le0\end{cases}$ |    $\theta$     |      $\theta^2$      |
| 二项分布 |     $X\sim b(n,p)$      |                              \                               |      $np$       |      $np(1-p)$       |
| 正态分布 | $X\sim N(\mu,\sigma^2)$ | $f(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$ |      $\mu$      |      $\sigma^2$      |

### 数学期望和方差的一些性质

* $E(C)=C,D(C)=0$

* $E(CX)=CE(X),D(CX)=C^2D(X),D(X+C)=D(X)$

* $D(X)=E(X^2)-E^2(X)$  **“里外“一定不要忘了**

* $E(X+Y)=E(X)+E(Y)$（与$X,Y$独立性无关）

  $D(X+Y)=D(X)+D(Y)+2Cov(X,Y)$，特别的，如果$X,Y$无关，则$D(X+Y)=D(X)+D(Y)$

* $D(X)=0\ <=>\ P\{X=E(X)\}=1$

* 如果$X,Y$独立，则$E(XY)=E(X)E(Y)$





## 协方差、相关系数、独立性

*独立的定义*

### 定义和性质

协方差：$Cov(X,Y)=E\{[X-E(X)][Y-E(Y)]\}=E(XY)-E(X)E(Y)$

相关系数：$\rho_{_{XY}}=\frac{Cov(X,Y)}{\sqrt{D(X)}\sqrt{D(Y)}}$

协方差性质：

* 如果$X$和$Y$相互独立， 则$E(XY)=E(X)E(Y)$，故$Cov(X,Y)=0$

* $Cov(X,Y)=Cov(Y,X),Cov(X,X)=D(X)$

* $D(X+Y)=D(X)+D(Y)+2Cov(X,Y)$

* $Cov(aX,bY)=abCov(X,Y)$

  $Cov(X_1+X_2,Y)=Cov(X_1,Y)+Cov(X_2,Y)$
  
* ==注意！$Cov=0 \not=>$独立！==也就是$D(X+Y)=D(X)+D(Y)$不一定推出独立！

  > [一个反例，来自知乎](https://www.zhihu.com/question/20320800)


相关系数性质

* $|\rho_{_{XY}}|\le 1$

* $|\rho_{_{XY}}|= 1$的充要条件：$\exists\  \ a,b\ \  s.t.\ P\{Y=a+bX\}=1$

* 当$\rho_{_{XY}}=0$时，称$X$与$Y$不相关

* 不相关$\neq>$相互独立，但相互独立$=>$不相关（独立$=>\ Cov=0\ =>\ \rho_{_{XY}}=0\ =>$不相关）



### 协方差矩阵

定义：对于随机变量$X_i(i=1,2,\cdots,n)$

如果$c_{ij}=Cov(X_i,X_j)=E\{[X_i-E(X_i)][X_j-E(X_j)]\}\ \ \ \ (i,j=1,2,\cdots,n)$都存在

则称$\textbf{C}=\left(\begin{array}{cccc} c_{11} & c_{12} & \cdots & c_{1n} \\ c_{21} & c_{22} & \cdots & c_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ c_{n1} & c_{n2} & \cdots & c_{nn}\end{array}\right)$为协方差矩阵








## 二维正态分布

对于$(X,Y)\sim N(\mu_1,\mu_2,\sigma_1,\sigma_2,\rho)$

概率论密度函数：$f(x,y)=\frac 1 {2\pi \sigma_1\sigma_2 \sqrt{1-\rho^2}}\exp\{\frac{-1}{2(1-\rho^2)}[\frac{(x-\mu_1)^2}{\sigma^2_1}-2\rho\frac{(x-\mu_1)(y-\mu_2)}{\sigma_1\sigma_2}+\frac{(y-\mu_2)^2}{\sigma_2^2}]\}$

边缘分布：就是一维的正态分布

对于二维正态分布，不相关、相互独立、$\rho=0$相互等价：

对于二维正态分布$(X,Y)\sim N(\mu_1,\mu_2,\sigma_1,\sigma_2,\rho)$，有

$Cov(X,Y)=\rho\sigma_1\sigma_2$

$\rho_{_{XY}}=\frac{Cov(X,Y)}{\sqrt{D(X)}\sqrt{D(Y)}}=\rho$

也就是说二维正态分布的概率密度中的参数$\rho$就是$X,Y$的相关系数，因此其分布完全可以用$X,Y$的期望、方差、相关系数决定

而因为二维正态分布中$X,Y$独立的充要条件是$\rho=0$，结合上述公式，可以得出**对于二维正态分布，不相关和相互独立充要**





# 大数定理和中心极限定理

## 切比雪夫不等式

设随机变量$X$具有数学期望$E(X)=\mu$，方差$D(X)=\sigma^2$，则对于$\forall \epsilon>0$，不等式$P\{|X-\mu|\ge\epsilon\}\le\frac{\sigma^2}{\epsilon^2}$成立

切比雪夫不等式本质是讨论了$|X-\mu|\ge\epsilon$的可能性

## 弱大数定理（辛钦大数）

设$X_1,X_2,\cdots$相互独立，服从同一分布的随机变量序列，且具有数学期望$E(X_k)=\mu\ (k=1,2,\cdots )$作前$n$个变量的算术平均$\frac 1 n \sum\limits_{k=1}\limits^{n}X_k$，则对于$\forall \epsilon>0$，有

$\lim \limits_{n\to \infty}P\{|\frac 1 n \sum\limits_{k=1}\limits^{n}X_k-\mu|<\epsilon\}=1$

这种形式也可以表达成：$\overline{X}\stackrel{P}{\longrightarrow}\mu$，即序列$\overline{X}=\frac 1 n \sum\limits_{k=1}\limits^{n}X_k$依概率收敛于$\mu$

## 伯努利大数定理

设$f_A$是$n$次独立重复试验中事件$A$发生的次数，$p$是事件$A$在每次试验中发生的概率，则对于$\forall \epsilon >0$有

$\lim \limits_{n\to \infty}P\{|\frac{f_A}{n}-p|<\epsilon\}=1\ \ or\ \ \lim \limits_{n\to \infty}P\{|\frac{f_A}{n}-p|\ge\epsilon\}=0$

也就是实际事件中如果$n$充分大，可以用$\frac {f_A}{n}$来代替$p$

## 中心极限定理

设随机变量$X_1,X_2,\cdots,X_n,\cdots$相互独立，服从同一分布，且具有数学期望和方差：$E(X_k)=\mu,D(X_k)=\sigma^2>0\ (k=1,2,\cdots)$

则随机变量之和$\sum\limits_{k=1}\limits^{n}X_k$的标准化变量$Y_n=\frac{\sum\limits_{k=1}\limits^{n}X_k-E(\sum\limits_{k=1}\limits^{n}X_k)}{\sqrt{D(\sum\limits_{k=1}\limits^{n}X_k)}}=\frac{\sum\limits_{k=1}\limits^{n}X_k-n\mu}{\sqrt{n}\sigma}$的分布函数$F_n(x)$对于$\forall x$满足：

$\lim \limits_{n\to \infty}F_n(x)=\lim\limits_{n\to \infty}P\{Y_n\le x\}=\Phi(x)$

也就是$n$充分大的时候$Y_n\sim N(0,1)$

## 李雅普诺夫定理

设随机变量$X_1,X_2,\cdots,X_n,\cdots$相互独立，服从同一分布，且具有数学期望和方差：$E(X_k)=\mu_k,D(X_k)=\sigma_k^2>0\ (k=1,2,\cdots)$

记$B_n^2=\sum\limits_{k=1}\limits^{n}\sigma^2_k$

若$\exists \delta>0$使得当$\ n\to\infty$时，$\frac 1 {B_n^{2+\delta}}\sum\limits_{k=1}\limits^{n}E\{|X_k-\mu_k|^{2+\delta}\}\to 0$

则随机变量之和$\sum\limits_{k=1}\limits^{n}X_k$的标准化变量$Z_n=\frac{\sum\limits_{k=1}\limits^{n}X_k-E(\sum\limits_{k=1}\limits^{n}X_k)}{\sqrt{D(\sum\limits_{k=1}\limits^{n}X_k)}}=\frac{\sum\limits_{k=1}\limits^{n}X_k-\sum\limits_{k=1}\limits^{n}\mu_k}{B_n}$的分布函数$F_n(x)$对于$\forall x$满足

$\lim \limits_{n\to \infty}F_n(x)=\lim \limits_{n\to \infty}P\{\frac{Z_n}{B_n}\le x\}=\Phi(x)$

## 棣莫弗-拉普拉斯定理

设随机变量$\eta_n\ \ (n=1,2,\cdots)$服从参数为$n,p\ \ (0<p<1)$的二项分布，则对于$\forall x$，有

$\lim \limits_{n\to \infty}P\{\frac{\eta_n-np}{\sqrt{np(1-p)}}\le x\}=\Phi(x)$

实际上此定理是由中心极限定理推导而来（假设每一次试验独立）

## 这章公式的推导过程

切比雪夫（已知$\epsilon,\sigma$）  =>  辛钦大数（已知$\epsilon$有$\sigma$，$X_i$独立同分布）  =>  伯努利大数定理（已知发生概率$p$且独立同分布）





# 抽样分布

==抽样分布中，每一次都当作独立试验==

## 基本概念

$X_i$指样本，$x_i$指观察值

### 样本平均值$\overline X$

$\overline{X}=\frac{1}{n}\sum\limits_{i=1}^{n}X_i$

### 样本方差$S^2$

$S^2=\frac{1}{n-1}\sum\limits_{i=1}\limits^{n}(X_i-\overline{X})^2=\frac{1}{n-1}(\sum\limits_{i=1}\limits^{n}X_i^2-n\overline{X}^2)$

注意分母是$n-1$，最右边的式子可以通过中间式子展开推导出

### 样本标准差$S$

$S=\sqrt{S^2}$

求的时候先求$S^2$再开根号即可

### 样本的$k$阶（原点）矩$A_k$

$A_k=\frac{1}{n}\sum\limits_{i=1}^{n}X_i^k\ \ \ (k=2,3,\cdots)$

一般用在参数估计上

### 样本的$k$阶中心矩$B_k$

$B_k=\frac{1}{n}\sum\limits_{i=1}^{n}(X_i-\overline{X})^k\ \ \ (k=2,3,\cdots)$

### 经验分布函数$F_n(x)$

指使用观察值的分布函数，在样本个数$n$充分大时依概率逼近分布函数$F(x)$

$S(x),-\infty<x<+\infty$表示$X_1,X_2,\cdots,X_n$中不大于$x$的随机变量个数

$F_n(x)=\frac 1 n S(x)$

### 上位点

如果$P(T>T_{\alpha}(\theta))=\alpha$，则称$T_{\alpha}(\theta)$是上$\alpha$分位点​

这里注意，$T$是分布的表达式，而$T_{\alpha}(\theta)$是一个常数

## 标准正态分布$z$

对于一般的正态分布$X\sim N(\mu,\sigma^2)$，有$\frac{X-\mu}{\sigma}\sim N(0,1)$，$N(0,1)$也就是标准正态分布



## $\chi^2$分布

### 定义

设$X_1,X_2,...,X_n$时来自总体$N(0,1)$的样本，则统计量

$\chi^2=X_1^2+X_2^2+\cdots+X_n^2$

服从自由度为$n$的$\chi^2$分布，记为$\chi^2\sim\chi^2(n)$，$\chi^2$分布不是轴对称的

注意如果$X\sim (\mu,\sigma^2)$，可以得到$\sum\limits_{i=1}\limits^{n}\frac{(x_i-\mu)^2}{\sigma^2}\sim \chi^2(n)$，这个在有些推导中很有用

### 可加性

设$\chi^2_1\sim\chi^2(n_1),\chi_2^2\sim\chi^2(n_1)$并且$\chi_1^2,\chi_2^2$相互独立，则

$\chi_1^2+\chi_2^2\sim\chi^2(n_1+n_2)$

### 数学期望和方差

$E(\chi^2)=n,D(\chi^2)=2n$

### 上分位点

对于给定正数$\alpha,0<\alpha<1$满足

$P\{\chi^2>\chi^2_{\alpha}(n)\}=\alpha$

的点$\chi_{\alpha}^2(n)$就是$\chi^2(n)$分布上的上$\alpha$分位点

一般通过查表法得到：

当$n>40$（充分大）的时候，可以近似有

$\chi^2_{\alpha}\approx\frac 1 2 (z_{\alpha}+\sqrt{2n-1})^2$

其中$z_{\alpha}$为标准正态分布的上$\alpha$分位点



## $t$分布

### 定义

设$X\sim N(0,1),Y\sim \chi^2(n)$，其中$X$，$Y$相互独立，则称随即变量

$t=\frac{X}{\sqrt{Y/n}}$

服从自由度为$n$的$t$分布，记为$t\sim t(n)$

注意$t$分布的概率密度函数是偶函数

### 上分位点

对于给定正数$\alpha,0<\alpha<1$满足

$P\{t>t_{\alpha}(n)\}=\alpha$

的点$t_{\alpha}(n)$就是$t(n)$分布的上$\alpha$分位点

由对称性：$t_{1-\alpha}(n)=t_{\alpha}(n)$

在$n>45$（充分大）的时候

$t_{\alpha}\approx z_{\alpha}$



## F分布

### 定义

设$U\sim \chi^2(n_1),V\sim \chi^2(n_2)$，且$U$、$V$相互独立，则称随机变量

$F=\frac{U/n_1}{V/n_2}$

服从自由度为$(n_1,n_2)$的$F$分布，记为$F\sim F(n_1,n_2)$

从定义易知：$\frac{1}{F}\sim F(n_2,n_1)$

$F$分布不是轴对称的

### 上分位点

对于给定正数$\alpha,0<\alpha<1$满足

$P\{F>F_{\alpha}(n_1,n_2)\}=\alpha$

的点$F_{\alpha}(n_1,n_2)$就是$F(n_1,n_2)$的上$\alpha$分位点

$F$分布上分位点有：$F_{1-\alpha}(n_1,n_2)=\frac{1}{F_{\alpha(n_2,n_1)}}$



## 正态分布总体的样本均值、样本均值方差的分布

### 一般情况下样本均值和样本均值方差

先讨论一般情况

设总体$X$（只需要均值和方差存在）均值为$\mu$，方差为$\sigma^2$（这里的$\mu,\sigma^2$是题目中呢公式给出的），$X_1,X_2,\cdots,X_n$是来自$X$的一个样本，$\overline{X}$、$S^2$分别是样本均值和样本方差，则

$E(\overline{X})=\mu,D(\overline{X})=\frac{\sigma^2}{n}$

通过定义可以知：$E(S^2)=\sigma^2$



==一定要注意以下全部针对正态分布讨论的==

### 正态分布均值的分布

设$X_1,X_2,\cdots,X_n$是来自总体$N(\mu,\sigma^2)$的样本，$\overline{X}$、$S^2$分别是样本均值和样本方差（下同）

$\overline{X}\sim N(\mu,\sigma^2/n)$

### 单正态总体重要定理

$\frac{(n-1)S^2}{\sigma^2}\sim \chi^2(n-1)$

$\frac{\overline{X}-\mu}{S/\sqrt{n}}\sim t(n-1)$

$\overline {X}$与$S^2$相互独立

### 双正态总体重要定理

设$X_1,X_2,\cdots,X_{n_1}$与$Y_1,Y_2,\cdots,Y_{n_2}$分别是来自正态总体$N(\mu_1,\sigma^2_1)$和$N(\mu_2,\sigma^2_2)$的样本，且样本之间（随机变量$X_1,X_2,\cdots,X_{n_1}$与$Y_1,Y_2,\cdots,Y_{n_2}$）==相互独立==

设$\overline {X}=\frac{1}{n}\sum\limits_{i=1}\limits^{n_1}X_i,\overline {Y}=\frac{1}{n}\sum\limits_{i=1}\limits^{n_1}Y_i$分别是两个样本的均值

且$\begin{cases}S_1^2=\frac{1}{n_1-1}\sum\limits_{i=1}\limits^{n_1}(X_i-\overline{X})^2=\frac{1}{n_1-1}(\sum\limits_{i=1}\limits^{n_1}X_i^2-n_1\overline{X})\\S_2^2=\frac{1}{n_2-1}\sum\limits_{i=1}\limits^{n_2}(X_i-\overline{X})^2=\frac{1}{n_2-1}(\sum\limits_{i=1}\limits^{n_2}X_i^2-n_2\overline{X})\end{cases}$分别为两个样本的方差

有以下结论：

* $\frac{S^2_1/S^2_2}{\sigma^2_1/\sigma^2_2}\sim F(n_1-1,n_2-1)$

* 当$\sigma^2_1=\sigma^2_2=\sigma^2$

  $\frac{(\overline{X}-\overline{Y})-(\mu_1-\mu_2)}{S_w\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}}\sim t(n_1+n_2-2)$

  其中$S^2_w=\frac{(n_1-1)S1^2+(n_2-1)S2^2}{n_1+n_2-2},S_w=\sqrt{S_w^2}$

  

# 参数估计

## 点估计

### 定义

设总体$X$的分布函数$F(x;\theta)$的==形式已知==，$\theta$是待估参数，$X_1,X_2,\cdots,X_n$是$X$的一个样本，$x_1,x_2,\cdots,x_n$是相应的一个样本值

点估计问题就是构造统计量$\hat{\theta}(X_1,X_2,\cdots,X_n)$（这个本质是一个函数），用它的观察值$\hat{\theta}(x_1,x_2,\cdots,x_n)$作为未知参数$\theta$的近似值

所以我们称$\hat{\theta}(X_1,X_2,\cdots,X_n)$为$\theta$的估计量，称$\hat{\theta}(x_1,x_2,\cdots,x_n)$为$\theta$的估计值



### 矩估计

**整个过程总结起来就一句话：根据已知的分布规律和参数写出原点矩，用样本矩代替原点矩，解出参数**

若$X$为连续型随机变量，概率密度已知为：$f(x;\theta_1,\theta_2,\cdots,\theta_n)$

若$X$为离散型随机变量，分布律已知为：$P\{X=x\}=p(x;\theta_1,\theta_2,\cdots,\theta_n)$

样本矩$\mu_l=E(X^l)=\begin{cases}\int_{-\infty}^{\infty}x^lf(x;\theta_1,\theta_2,\cdots,\theta_n)\rm{dx} \\ \sum\limits_{x\in R_x}x^l p(x;\theta_1,\theta_2,\cdots,\theta_n)\end{cases}(l=1,2,\cdots,k)$，这里$\begin{cases}f(x;\theta_1,\theta_2,\cdots,\theta_n)\\p(x;\theta_1,\theta_2,\cdots,\theta_n)\end{cases}$是一个函数，根据已知的形式带入参数求出来



原点矩$A_l=\frac{1}{n}\sum\limits_{i=1}\limits^{n}X_i^l$，使用的是观察值来求

最后根据列出的式子中所有的$\mu_i$用$A_i$代换，对应的函数即矩估计量，求解出参数$\theta$即矩估计值



对于任意有期望$\mu$和标准差$\sigma^2$的分布，其==矩估计值==是确定的：$\begin{cases}\hat{\mu}=\overline{X} \\ \hat{\sigma^2}=\frac 1 n \sum\limits_{i=1}\limits^{n}(X_i-\overline{X})^2\end{cases}$

在写矩估计量的表达式的时候$\overline{X},\hat{\sigma^2}$可以用$A_1,A_2$计算：$\begin{cases}\overline{X}=A_1 \\ \hat{\sigma^2}= A_2-A_1^2\end{cases}$

同样写表达式的时候可以用$\overline{x}$代替$\frac{\sum\limits_{i=1}\limits^{n}x_i}{n}$





### 最大似然估计

**整个过程就一句话：写出带参数的多次取样后的概率函数，带入样本值，求这个函数值最大的时候的参数**

#### 离散型

若总体$X$为离散型，分布律$P\{X=x\}=p(x;\theta),\theta\in \Theta$形式已知，$\theta$是待估参数，$\Theta$是$\theta$的取值范围

设$X_1,X_2,\cdots,X_n$是$X$的一个样本（自然相互独立），则$X_1,X_2,\cdots,X_n$的联合概率分布律是：

$\prod\limits_{i=1}\limits^{n}p(X_i;\theta)$

设$x_1,x_2,\cdots,x_n$是$X_1,X_2,\cdots,X_n$的样本值，则事件$\{X_i=x_i,i=1,2,\cdots,n\}$发生概率是
$L(\theta)=L(x_1,x_2,\cdots,x_n;\theta)=\prod\limits_{i=1}\limits^{n}p(x_i,\theta),\theta\in \Theta$

这里只有$\theta$一个参数变量，只要求出$\theta$值是多少时函数$L(\theta)$最大即可

即$L(x_1,x_2,\cdots,x_n;\hat{\theta})=\max\limits_{\theta\in\Theta}L(x_1,x_2,\cdots,x_n;\theta)$

记$\hat{\theta}$为$\hat{\theta}(x_1,x_2,\cdots,x_n)$，称为$\theta$的最大似然估计值，相应的统计量$\hat{\theta}(X_1,X_2,\cdots,X_n)$为最大似然估计量

#### 连续型

若总体$X$为连续型，密度函数$f(x;\theta),\theta\in\Theta$的形式已知，$\theta$是待估参数，$\Theta$是$\theta$的取值范围

设$X_1,X_2,\cdots,X_n$是$X$的一个样本（自然相互独立），则$X_1,X_2,\cdots,X_n$的联合概率分布律是：

$\prod\limits_{i=1}\limits^{n}f(x_i;\theta)$

则$(X_1,X_2,\cdots,X_n)$在点$(x_1,x_2,\cdots,x_n)$的邻域内概率为

$\prod\limits_{i=1}\limits^{n}f(x_i;\theta)\rm{dx_i}$，考虑到$\rm{dx_i}$与$\theta$无关，故只考虑

$L(\theta)=L(x_1,x_2,\cdots,x_n;\theta)=\prod\limits_{i=1}\limits^{n}f(x_i,\theta),\theta\in \Theta$

这里只有$\theta$一个参数变量，只要求出$\theta$值是多少时函数$L(\theta)$最大即可

即$L(x_1,x_2,\cdots,x_n;\hat{\theta})=\max\limits_{\theta\in\Theta}L(x_1,x_2,\cdots,x_n;\theta)$

记$\hat{\theta}$为$\hat{\theta}(x_1,x_2,\cdots,x_n)$，称为$\theta$的最大似然估计值，相应的统计量$\hat{\theta}(X_1,X_2,\cdots,X_n)$为最大似然估计量



#### 对数似然方程

最大似然估计即求$\frac{\rm{d}}{\rm{d\theta}}L(\theta)=0$的$\theta$，可以利用对数化简方程为

$\frac{d}{d\theta}ln\ L(\theta)=0$，称为最大似然方程

可以利用此化简乘法，甚至把无关的系数全部约去（$L(\theta)=A\cdot f(\theta)\stackrel{ln}{\longrightarrow} ln\ L(\theta)=lnA+ln[f(\theta)]$，这里的$A$就可以直接约去）



#### 多参数情形

对于多个参数$\theta_1,\theta_2,\cdots,\theta_k$的情况，似然函数$L$是这些参数的函数

分别令$\begin{cases} \frac{\partial}{\partial \theta_i}L=0 \\ \ \ \ \ \ \ \  or\\\frac{\partial}{\partial\theta_i}ln\ L=0\end{cases}i=1,2,3\cdots,k$

即可解得各个参数的极大似然值



#### 最大似然估计的不变性

设$\theta$的函数$u=u(\theta),\theta\in \Theta$具有单值反函数$\theta=\theta(u),u\in \upsilon$，又假设$\hat{\theta}$是$X$的概率分布中参数$\theta$的最大似然估计，则$\hat{u}=u(\hat{\theta})$是$u(\theta)$的最大似然估计

即如果要求$U=f(\theta)$的最大似然估计，如果满足上述条件直接把$\hat{\theta}$代入即可(注意反函数单值一定单调)



## 常见分布的估计量

|          分布           |                            矩估计                            |                         最大似然估计                         |
| :---------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| $X\sim N(\mu,\sigma^2)$ | $\hat{\mu}=\overline{X},\hat{\sigma^2}=\frac 1 n\sum\limits_{i=1}\limits^{n}(X_i-\overline{X}^2)$ | $\hat{\mu}=\overline{X},\hat{\sigma^2}=\frac 1 n\sum\limits_{i=1}\limits^{n}(X_i-\overline{X}^2)$ |
|     $X\sim U(a,b)$      | $\hat{a}=\overline{X}-\sqrt{\frac 3 n \sum\limits_{i=1}\limits^{n}(X_i-\overline{X})^2},\hat{b}=\overline{X}+\sqrt{\frac 3 n \sum\limits_{i=1}\limits^{n}(X_i-\overline{X})^2}$ | $\hat{a}=\min\limits_{1\le i \le n}X_i,\hat{b}=\max\limits_{1\le i \le n}X_i$ |
|                         |                                                              |                                                              |

备注：

* 平均分布的最大似然估计用了奇怪的技巧，具体怎么求出来的见书P155
* 

## 估计量的评估标准

### 无偏性

若估计量$\hat{\theta}(X_1,X_2,\cdots,X_n)$==（这是个求出来的函数，与$X_1,X_2,\cdots $有关，也可以用别的符号表示，比如$S^2 $）==的数学期望$E(\hat{\theta})$存在，且对于$\forall \theta\in \Theta$有$E(\hat{\theta})=\theta$==（左边是关于$X_i$等的式子，右边的$\theta$是参数）==，则称$\hat{\theta}$是$\theta$的无偏估计量

注意，对于一个有方差的分布$\sigma^2$，$E(S^2)=\sigma^2$，即$S^2$是$\sigma^2$的无偏估计(证明见课本P142)

### 有效性

设$\hat{\theta_1}=\hat{\theta_1}(X_1,X_2,\cdots,X_n)$与$\hat{\theta_2}=\hat{\theta_2}(X_1,X_2,\cdots,X_n)$都是$\theta$的无偏估计量

对于$\forall \theta\in\Theta$有$D(\hat{\theta_1})\le D(\hat{\theta_2})$且$\exists \theta\in \Theta$使上式中的不等号成立，则称$\hat{\theta_1}$较$\hat{\theta_2}$有效

### 相合性

设$\hat{\theta}(X_1,X_2,\cdots,X_n)$为参数$\theta$的估计量，若$\forall \theta\in\Theta$，当$n\to \infty$时$\hat{\theta}(X_1,X_2,\cdots,X_n)$依概率收敛于$\theta$，则称$\hat{\theta}$为$\theta$的相合估计量

即：$\forall\theta\in\Theta,\forall\epsilon>0,s.t. \lim\limits_{n\to\infty}\{|\hat{\theta}-\theta|<\epsilon\}=1$，则称$\hat{\theta}$是$\theta$的相合估计量



## 区间估计

### 置信区间定义

设总体$X$的分布函数$F(x;\theta)$含有一个未知参数$\theta,\theta\in\Theta$，对于给定的值$\alpha(0<\alpha<1)$，若来自$X$的样本$X_1,X_2,\cdots,X_n$，确定两个统计量$\underline{\theta}=\underline{\theta}(X_1,X_2,\cdots,X_n)$和$\overline{\theta}=\overline{\theta}(X_1,X_2,\cdots,X_n)$并且$\underline{\theta}<\overline{\theta}$，对于$\forall \theta\in\Theta$满足$P\{\underline{\theta}(X_1,X_2,\cdots,X_n))<\theta<\overline{\theta}(X_1,X_2,\cdots,X_n)\}\ge 1-\alpha$，则称置信区间$(\underline{\theta},\overline{\theta})$是$\theta$的置信书评为$1-\alpha$的置信区间，$\underline{\theta}$和$\overline{\theta}$的置信下限、置信上限，$1-\alpha$为置信水平

### 一般情况下置信区间的求法

1. 寻求一个样本$X_1,X_2,\cdots,X_n$和$\theta$的函数$W=W(X_1,X_2,\cdots,X_n;\theta)$，使得$W$的分布不依赖于$\theta $以及其他未知参数（样本总数$n$是已知量）
2. 对于$\forall \ (1-\alpha)$，求出两个常数$a,b$（一般用分布的上分位点（与$1-\alpha$有关）表示）使得$P\{a<W(X_1,X_2,\cdots,X_n;\theta)<b\}=1-\alpha$
3. 从$a<W(X_1,X_2,\cdots,X_n;\theta)<b\ $得到与之等价的$\underline{\theta}<\theta<\overline{\theta}$，其中$\underline{\theta}=\underline{\theta}(X_1,X_2,\cdots,X_n)$和$\overline{\theta}=\overline{\theta}(X_1,X_2,\cdots,X_n)$都是统计量（用抽出的样$X_i$组成的函数），那么$(\underline{\theta},\overline{\theta})$就是$\theta$一个置信水平为$1-\alpha$的置信区间
4. 这里的$\theta=\theta(X_i)$函数一般取对称的分位点值，如对于概率$1-\alpha$，
   * $\chi^2$分布取$\chi^2_{1-\alpha/2},\chi^2_{\alpha/2}$，也就是概率$1-\alpha/2,\alpha/2$（注意由上位点的定义$1-\alpha/2>\alpha/2$，相减为$1-\alpha$）对应的上分位点
   * $F$分布取$F_{1-\alpha/2},F_{\alpha/2}$，和$\chi^2$分布一样
   * $t$分布取$-t_{\alpha/2},t_{\alpha/2}$（因为$t$分布对称，即$t_{1-\alpha/2}=-t_{\alpha/2}$）
   * 标准正态分布$z$同$t$分布一样

如果是取单侧置信区间则对应双侧的方法取对应即可

推导过程的示例见下“方差$\sigma^2$（即稳定性）的置信区间（$\mu$已知）”，注意那题因为函数特殊，需要用两个分布来求

## 正态总体均值与方差的区间估计

### 单个总体$N(\mu,\sigma^2)$的情况

####  均值$\mu$的置信区间（$\sigma^2$已知）

用$\frac{\overline{X}-\mu}{\sigma/\sqrt{n}}\sim N(0,1)$推导，可以得出：

$\mu$的一个置信水平为$1-\alpha$的置信区间是$(\overline{X}\pm\frac{\sigma}{\sqrt{n}}z_{\alpha/2})$

#### 均值$\mu$的置信区间（$\sigma^2$未知）

用$\frac{\overline{X}-\mu}{S/\sqrt{n}}\sim t(n-1)$，可以得出：

$\mu$的一个置信水平为$1-\alpha$的置信区间是$(\overline{X}\pm\frac{S}{\sqrt{n}}t_{\alpha/2}(n-1))$

#### 方差$\sigma^2$（即稳定性）的置信区间（$\mu$已知）

用$\frac{\overline{X}-\mu}{\sigma/\sqrt{n}}\sim N(0,1)$推导

则方差$\sigma^2$的一个置信水平为$1-\alpha$的置信区间$(\frac{\overline{X}-\mu}{\sqrt{n}z_{\alpha/2}},)$



过程：（如果是求上/下置信区间，只讨论一种即可）

置信区间下限：

$P\{\frac{\overline X-\mu}{\sigma/\sqrt{n}}\ge z_{c_1}\}=c_1,P\{\frac{\overline X-\mu}{\sigma/\sqrt{n}}\ge z_{c_2}\}=c_2$，设这里$c_2>c_1$（注意此时$z_{c_2}<z_{c_1}$）

则$P\{z_{c_1}\ge\frac{\overline X-\mu}{\sigma/\sqrt{n}}\ge z_{c_2}\}=c_2-c_1$，令$c_2-c_1=1-\alpha$

一般设：$c_2=1-\alpha/2,c_1=\alpha/2$，这里取$z_{\alpha/2}$只是习惯（由于$\alpha<1$，所以$1-\alpha/2>\alpha/2$，结合$c_1,c_2$大小关系对应的）

所以：$P\{z_{\alpha/2}\ge\frac{\overline X-\mu}{\sigma/\sqrt{n}}\ge z_{1-\alpha/2}\}=1-\alpha$

由于$z_{1-x}=-z_{x}$（对称性），这也是使用正态分布的时候的特殊性

则：$P\{z_{\alpha/2}\ge\frac{\overline X-\mu}{\sigma/\sqrt{n}}\ge -z_{\alpha/2}\}=1-\alpha$

变化即可得：$P\{\sigma^2\ge \frac{n(\overline{X}-\mu)^2}{z^2_{\alpha/2}}\}=1-\alpha$

置信区间上限：

使用$\sum\limits_{i=1}\limits^{n}\frac{(x_i-\mu)^2}{\sigma^2}\sim \chi^2(n)$推导即可，方法和上一样



#### 方差$\sigma^2$（即稳定性）的置信区间（$\mu$未知）

用$\frac{(n-1)S^2}{\sigma^2}\sim \chi^2(n-1)$推导，可以得出

则方差$\sigma^2$的一个置信水平为$1-\alpha$的置信区间$(\frac{(n-1)S^2}{\chi^2_{\alpha/2}(n-1)},\frac{(n-1)S^2}{\chi^2_{1-\alpha/2}(n-1)})$

也可以得出标准差$\sigma$的一个置信水平为$1-\alpha$的置信区间$(\frac{\sqrt{n-1}S}{\sqrt{\chi^2_{\alpha/2}(n-1)}},\frac{\sqrt{n-1}S}{\sqrt{\chi^2_{1-\alpha/2}(n-1)}})$



### 两个总体$X\sim N(\mu_1,\sigma^2_1),Y\sim N(\mu_2,\sigma^2_2)$的情况

设样本数分别为$n_1,n_2$，样本相互独立，样本方差、样本估值：$\overline{X},\overline{Y},S_1^2,S_2^2$

#### 两个总体均值$\mu_1-\mu_2$的置信区间（已知$\sigma_1^2$和$\sigma^2_2$）

由$\overline{X}\sim N(\mu_1,\sigma_1^2/n_1),\overline{Y}\sim N(\mu_2,\sigma_2^2/n_2)\ =>\ \overline{X}-\overline{Y}\sim N(\mu_1-\mu_2,\frac{\sigma_1^2}{n_1}+\frac{\sigma^2_2}{n_2})\ =>\ \frac{(\overline{X}-\overline{Y})-(\mu_1-\mu_2)}{\sqrt{\frac{\sigma^2_1}{n_1}+\frac{\sigma^2_2}{n_2}}}\sim N(0,1)\ \ $可以得出

$\mu_1-\mu_2$的一个置信水平为$1-\alpha$的置信区间$(\overline{X}-\overline{Y}\pm z_{\alpha/2}\sqrt{\frac{\sigma^2_1}{n_1}+\frac{\sigma_2^2}{n_2}})$



#### 两个总体均值$\mu_1-\mu_2$的置信区间（已知$\sigma_1^2=\sigma^2_2=\sigma^2$但是$\sigma^2$未知）

由$t$分布$\frac{(\overline{X}-\overline{Y})-(\mu_1-\mu_2)}{S_w\sqrt{\frac 1 {n_1}+\frac 1 {n_2}}}\sim t(n_1+n_2-2)$推导可知：

$\mu_1-\mu_2$的一个置信水平为$1-\alpha$的置信区间为：$(\overline{X}-\overline{Y}\pm t_{\alpha/2}(n_1+n_2-2)S_w\sqrt{\frac 1 {n_1}+\frac 1 {n_2}})$

其中$S_w^2=\frac{(n_1-1)S_1^2+(n_2-1)S^2_2}{n_1+n_2-2},S_w=\sqrt{S^2_w}$



#### 两个总体方差比$\sigma_1^2/\sigma_2^2$的置信区间（$\mu_1,\mu_2$未知）

由$\frac{S_1^2/S_2^2}{\sigma_1^2/\sigma_2^2}\sim F(n_1-1,n_2-1)$可推得

$\sigma_1^2/\sigma_2^2$得一个置信水平为$1-\alpha$的置信区间为$(\frac{S_1^2}{S_2^2}\frac{1}{F_{\alpha/2}(n_1-1,n_2-1)},\frac{S_1^2}{S_2^2}\frac{1}{F_{1-\alpha/2}(n_1-1,n_2-1)})$

如果$\sigma_1^2/\sigma_2^2$区间内包含$1$就认为$\sigma_1^2,\sigma_2^2$没有显著差别



### $(0-1)$分布参数的区间估计

设有以容量$n>50$的大样本，它来自$(0-1)$分布的总体$X$，$X$的分布律为

$f(x;p)=p^x(1-p)^{1-x}$

其中$p$为未知参数

通过中心极限定理可以推导得：

$p$得一个近似的置信水平为$1-\alpha$的置信区间为$(p_1,p_2)$

其中：$\begin{cases}p_1=\frac 1 {2a}(-b-\sqrt{b^2-4ac}) \\ p_2=\frac 1 {2a}(-b+\sqrt{b^2-4ac})\end{cases}$，$\begin{cases}a=n+z^2_{\alpha/2} \\ b=-(2n\overline{X}+z^2_{\alpha/2}) \\ c=n\overline{X}^2\end{cases}$



## 单正态分布均值$\mu$单侧置信区间

对于正态分布$N(\mu,\sigma^2)$，$\sigma^2$未知，可以使用两侧置信区间求解时的类似方法得到：

$\mu$的置信水平为$1-\alpha$的单侧置信区间为：

$(-\infty,\overline{X}+t_{\alpha}(n-1)]\frac{S}{\sqrt{n}})$或者$(\overline{X}-t_{\alpha}(n-1)\frac{S}{\sqrt{n}},\infty)$

也就是只需要将原置信区间的上下限中的$\alpha/2$改成$\alpha$即可



